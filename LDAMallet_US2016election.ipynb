{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Mallet Model notebook: Defamation in the US 2016 Presidential Election"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we implement the LDA Mallet Model and evaluate performance\n",
    "\n",
    "Link to reference: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#16buildingldamalletmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to identifying an approach for defamation detection in tweets, we aimed to understand the key topics discussed in the tweets using topic modeling. Topic models are a ubiquitous tool in text analysis because of their versatility in handling massive quantities of unlabeled text. Here, a topic refers to a group of words which seem to have a higher probability of appearing together. By running our corpus through a topic model, we were able to preview potential areas of influence in the strategies of our users in relation to defamation attempts. \n",
    "\n",
    "Although there are many variants of topic models in literature, we used the MALLET (MAchine Learning for LanguagE Toolkit) (\\cite{McCallumMALLET}) model for our analysis. MALLET is an excellent tool for when one aims to use topic modeling as an initial exploratory tool in the data because it is a scalable implementation of Gibbs sampling which works very well for expediting clustering. We first ran the model to do an efficient search for the optimal amount of topics in our corpus. The search range spanned from 5 to 35 topics with a step size of 3. As a result, the optimal number of topics was 26 with a highest coherence value of 39.32. The primary results of the model are shown in Figure \\ref{fig:num_tweets_topic} where we see a labeled 26 topics along the y-axis, and the number of tweets pertaining to each topic along the x-axis. Given the context of the US elections, and American current events in general, it is reasonable that the main topics include Trump, Clinton, Barack Obama, terrorism, economics, and gun control. Overall, majority of the identified topics are sensitive to the US and are a clear choice for attempts at at influencing opinions. Furthermore, in Figure \\ref{fig:topic_freq_date}, for each of the topics, we can see how tweet frequency changes by date between 2014 and 2017. What stands out is the peaks of tweets around Summer 2015, which is coincidentally also the starting time of the Trump campaign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T17:33:53.174022Z",
     "start_time": "2020-06-12T17:33:53.169139Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T17:49:32.965743Z",
     "start_time": "2020-06-12T17:49:32.961320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kristin.lomicka/Documents/BGSE_Courses/text_mining/Project'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:02:41.531552Z",
     "start_time": "2020-06-12T18:02:38.749522Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import pickle files\n",
    "import pickle\n",
    "\n",
    "# Tweets\n",
    "with open('clean_tweets', 'rb') as outputs:\n",
    "    tweets = pickle.load(outputs)\n",
    "\n",
    "# Model results\n",
    "\n",
    "with open('ldamallet_17', 'rb') as outputs:\n",
    "    optimal_model = pickle.load(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T17:50:21.269479Z",
     "start_time": "2020-06-12T17:50:21.266558Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load mallet file\n",
    "\n",
    "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "mallet_path = 'mallet-2.0.8/bin/mallet' # update this path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T17:39:22.824501Z",
     "start_time": "2020-06-12T17:39:09.636332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary and corpus needed for topic model\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(tweets)\n",
    "\n",
    "# Create Corpus\n",
    "texts = tweets\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Run LDA Mallet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T17:57:22.616805Z",
     "start_time": "2020-06-12T17:50:55.470217Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run LDA for a single k (# of topics)\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=17, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T20:46:45.902167Z",
     "start_time": "2020-06-12T20:46:29.116682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.145*\"rt\" + 0.031*\"vote\" + 0.019*\"cruz\" + 0.019*\"support\" + 0.018*\"https\" '\n",
      "  '+ 0.015*\"democrats\" + 0.014*\"poll\" + 0.012*\"ted\" + 0.012*\"retweet\" + '\n",
      "  '0.011*\"care\"'),\n",
      " (1,\n",
      "  '0.165*\"rt\" + 0.097*\"obama\" + 0.018*\"https\" + 0.015*\"russia\" + '\n",
      "  '0.013*\"obama\\'s\" + 0.013*\"party\" + 0.011*\"wall\" + 0.009*\"jobs\" + '\n",
      "  '0.009*\"dnc\" + 0.009*\"open\"'),\n",
      " (2,\n",
      "  '0.110*\"rt\" + 0.033*\"time\" + 0.022*\"years\" + 0.013*\"money\" + 0.013*\"million\" '\n",
      "  '+ 0.012*\"states\" + 0.010*\"change\" + 0.010*\"united\" + 0.010*\"days\" + '\n",
      "  '0.010*\"long\"'),\n",
      " (3,\n",
      "  '0.379*\"rt\" + 0.158*\"islam\" + 0.122*\"lesson\" + 0.122*\"today\\'s\" + 0.087*\"️\" '\n",
      "  '+ 0.016*\"️️\" + 0.008*\"religion\" + 0.007*\"peace\" + 0.004*\"\\u200d\" + '\n",
      "  '0.002*\"️️️\"'),\n",
      " (4,\n",
      "  '0.051*\"muslim\" + 0.034*\"muslims\" + 0.025*\"islamic\" + 0.021*\"isis\" + '\n",
      "  '0.017*\"terrorist\" + 0.014*\"terror\" + 0.013*\"refugees\" + 0.013*\"terrorists\" '\n",
      "  '+ 0.012*\"attacks\" + 0.011*\"terrorism\"'),\n",
      " (5,\n",
      "  '0.193*\"rt\" + 0.033*\"video\" + 0.021*\"watch\" + 0.020*\"\\'s\" + 0.017*\"https\" + '\n",
      "  '0.010*\"hey\" + 0.009*\"here\\'s\" + 0.009*\"wrong\" + 0.009*\"full\" + '\n",
      "  '0.008*\"fact\"'),\n",
      " (6,\n",
      "  '0.064*\"rt\" + 0.039*\"white\" + 0.032*\"black\" + 0.025*\"people\" + 0.022*\"house\" '\n",
      "  '+ 0.017*\"hate\" + 0.017*\"man\" + 0.015*\"amp\" + 0.014*\"death\" + '\n",
      "  '0.012*\"racist\"'),\n",
      " (7,\n",
      "  '0.170*\"rt\" + 0.064*\"america\" + 0.040*\"make\" + 0.036*\"great\" + 0.022*\"back\" '\n",
      "  '+ 0.019*\"–\" + 0.016*\"fight\" + 0.015*\"iran\" + 0.014*\"deal\" + '\n",
      "  '0.014*\"president\"'),\n",
      " (8,\n",
      "  '0.107*\"rt\" + 0.015*\"woman\" + 0.013*\"man\" + 0.012*\"york\" + 0.011*\"home\" + '\n",
      "  '0.011*\"http\" + 0.011*\"year\" + 0.010*\"school\" + 0.010*\"children\" + '\n",
      "  '0.010*\"prison\"'),\n",
      " (9,\n",
      "  '0.092*\"rt\" + 0.029*\"day\" + 0.028*\"love\" + 0.023*\"today\" + 0.016*\"life\" + '\n",
      "  '0.012*\"remember\" + 0.012*\"twitter\" + 0.011*\"happy\" + 0.011*\"makes\" + '\n",
      "  '0.010*\"true\"'),\n",
      " (10,\n",
      "  '0.183*\"rt\" + 0.028*\"uy41ohlqpejzkqhs\" + 0.024*\"stop\" + 0.022*\"law\" + '\n",
      "  '0.015*\"illegal\" + 0.014*\"ht\" + 0.013*\"immigration\" + 0.012*\"a3g4wu5athso\" + '\n",
      "  '0.011*\"put\" + 0.011*\"lies\"'),\n",
      " (11,\n",
      "  '0.033*\"police\" + 0.019*\"killed\" + 0.016*\"breaking\" + 0.015*\"isis\" + '\n",
      "  '0.015*\"attack\" + 0.014*\"shooting\" + 0.013*\"dead\" + 0.011*\"military\" + '\n",
      "  '0.011*\"shot\" + 0.011*\"st\"'),\n",
      " (12,\n",
      "  '0.137*\"rt\" + 0.041*\"amp\" + 0.034*\"media\" + 0.023*\"world\" + 0.022*\"https\" + '\n",
      "  '0.017*\"war\" + 0.016*\"truth\" + 0.013*\"liberal\" + 0.012*\"left\" + '\n",
      "  '0.011*\"political\"'),\n",
      " (13,\n",
      "  '0.213*\"trump\" + 0.045*\"president\" + 0.043*\"donald\" + 0.029*\"rt\" + '\n",
      "  '0.015*\"trump\\'s\" + 0.014*\"win\" + 0.012*\"supporters\" + 0.010*\"rally\" + '\n",
      "  '0.009*\"debate\" + 0.009*\"run\"'),\n",
      " (14,\n",
      "  '0.125*\"rt\" + 0.101*\"amp\" + 0.044*\"people\" + 0.032*\"american\" + 0.027*\"http\" '\n",
      "  '+ 0.018*\"https\" + 0.015*\"liberals\" + 0.014*\"free\" + 0.013*\"speech\" + '\n",
      "  '0.012*\"stand\"'),\n",
      " (15,\n",
      "  '0.143*\"rt\" + 0.037*\"news\" + 0.028*\"good\" + 0.027*\"women\" + 0.016*\"times\" + '\n",
      "  '0.016*\"cnn\" + 0.014*\"fake\" + 0.014*\"god\" + 0.012*\"show\" + 0.012*\"bill\"'),\n",
      " (16,\n",
      "  '0.086*\"hillary\" + 0.063*\"clinton\" + 0.020*\"fbi\" + 0.017*\"state\" + '\n",
      "  '0.014*\"report\" + 0.014*\"emails\" + 0.012*\"comey\" + 0.012*\"security\" + '\n",
      "  '0.011*\"email\" + 0.010*\"campaign\"')]\n",
      "\n",
      "Coherence Score:  0.40065084137381474\n"
     ]
    }
   ],
   "source": [
    "# Show Topics\n",
    "#optimal_model = ldamallet\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=optimal_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:01:52.811765Z",
     "start_time": "2020-06-12T18:01:52.805095Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find optimal number of topics\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_coherence_values(dictionary=id2word, corpus=corpus, texts=texts, start=5, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[3]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T20:46:29.113499Z",
     "start_time": "2020-06-12T18:02:49.439129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>police, killed, breaking, isis, attack, shooti...</td>\n",
       "      <td>[new, convoy, arrived]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>police, killed, breaking, isis, attack, shooti...</td>\n",
       "      <td>[civilians, killed, mosul]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>rt, white, black, people, house, hate, man, am...</td>\n",
       "      <td>[truly, know, know, true, paybacks, hell, pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>rt, day, love, today, life, remember, twitter,...</td>\n",
       "      <td>[remember, last, summer, dear, ️]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.1061</td>\n",
       "      <td>trump, president, donald, rt, trump's, win, su...</td>\n",
       "      <td>[us, gay, arriage, licsence, refused, clerk, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>rt, video, watch, 's, https, hey, here's, wron...</td>\n",
       "      <td>[former, president, jimmy, carter, begin, radi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>hillary, clinton, fbi, state, report, emails, ...</td>\n",
       "      <td>[new, trove, purported, ashley, madison, data,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>rt, islam, lesson, today's, ️, ️️, religion, p...</td>\n",
       "      <td>[today's, lesson, islam, ️, ️]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.1886</td>\n",
       "      <td>rt, woman, man, york, home, http, year, school...</td>\n",
       "      <td>[new, york, prison, escapee, david, sweat, ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.1805</td>\n",
       "      <td>rt, woman, man, york, home, http, year, school...</td>\n",
       "      <td>[subways, jared, fogle, faces, years, prison, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0            11.0              0.0886   \n",
       "1            1            11.0              0.1100   \n",
       "2            2             6.0              0.0886   \n",
       "3            3             9.0              0.0915   \n",
       "4            4            13.0              0.1061   \n",
       "5            5             5.0              0.1714   \n",
       "6            6            16.0              0.1369   \n",
       "7            7             3.0              0.1444   \n",
       "8            8             8.0              0.1886   \n",
       "9            9             8.0              0.1805   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  police, killed, breaking, isis, attack, shooti...   \n",
       "1  police, killed, breaking, isis, attack, shooti...   \n",
       "2  rt, white, black, people, house, hate, man, am...   \n",
       "3  rt, day, love, today, life, remember, twitter,...   \n",
       "4  trump, president, donald, rt, trump's, win, su...   \n",
       "5  rt, video, watch, 's, https, hey, here's, wron...   \n",
       "6  hillary, clinton, fbi, state, report, emails, ...   \n",
       "7  rt, islam, lesson, today's, ️, ️️, religion, p...   \n",
       "8  rt, woman, man, york, home, http, year, school...   \n",
       "9  rt, woman, man, york, home, http, year, school...   \n",
       "\n",
       "                                                Text  \n",
       "0                             [new, convoy, arrived]  \n",
       "1                         [civilians, killed, mosul]  \n",
       "2  [truly, know, know, true, paybacks, hell, pers...  \n",
       "3                  [remember, last, summer, dear, ️]  \n",
       "4  [us, gay, arriage, licsence, refused, clerk, k...  \n",
       "5  [former, president, jimmy, carter, begin, radi...  \n",
       "6  [new, trove, purported, ashley, madison, data,...  \n",
       "7                     [today's, lesson, islam, ️, ️]  \n",
       "8  [new, york, prison, escapee, david, sweat, ple...  \n",
       "9  [subways, jared, fogle, faces, years, prison, ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the dominant topic for each tweet\n",
    "\n",
    "def format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=texts)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T20:51:05.583309Z",
     "start_time": "2020-06-12T20:51:00.031380Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dominant_topic.to_csv('mallet17_topics_by_tweet.csv')\n",
    "df_dominant_topic = pd.read_csv('mallet17_topics_by_tweet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
